{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENSEA_API_KEY = os.getenv('OPENSEA_API_KEY')\n",
    "DUNE_API_KEY = os.getenv('DUNE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trades data\n",
    "I wrote a custom SQL query on Dune Analytics (open database for onchain data): https://dune.com/queries/3124232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 19:14:56,631 INFO numexpr.utils NumExpr defaulting to 8 threads.\n",
      "2023-10-24 19:14:57,712 INFO dune_client.api.base executing 3124232 on medium cluster\n",
      "2023-10-24 19:14:58,819 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n",
      "2023-10-24 19:15:00,461 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n",
      "2023-10-24 19:15:01,996 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n",
      "2023-10-24 19:15:03,433 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n",
      "2023-10-24 19:15:04,931 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n",
      "2023-10-24 19:15:06,399 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n",
      "2023-10-24 19:15:07,945 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n",
      "2023-10-24 19:15:09,576 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n",
      "2023-10-24 19:15:11,112 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n",
      "2023-10-24 19:15:12,656 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n",
      "2023-10-24 19:15:14,273 INFO dune_client.api.base waiting for query execution 01HDJ2YFSQ3ZY6QY87W2KFBDQW to complete: ExecutionState.EXECUTING\n"
     ]
    }
   ],
   "source": [
    "from dune_client.types import QueryParameter\n",
    "from dune_client.client import DuneClient\n",
    "from dune_client.query import QueryBase\n",
    "\n",
    "query = QueryBase(\n",
    "    query_id = 3124232,\n",
    "    params = [\n",
    "        QueryParameter.text_type(\n",
    "            name=\"nft_contract_address\",\n",
    "            value=\"0xbc4ca0eda7647a8ab7c2061c2e118a18a936f13d\"\n",
    "            ),\n",
    "        QueryParameter.text_type(\n",
    "            name=\"end_date\",\n",
    "            value=\"2023-09-30\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "dune = DuneClient.from_env()\n",
    "df = dune.run_query_dataframe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as csv\n",
    "df.to_csv(\"data/bayc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-read data (if needed)\n",
    "df = pd.read_csv(\"data/bayc.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean columns\n",
    "df.rename(columns={'amount_original':'trade_price'}, inplace=True)\n",
    "df = df[df['trade_price']!='<nil>']\n",
    "df['trade_price'] = df['trade_price'].astype(float)\n",
    "df['block_time'] = pd.to_datetime(df['block_time'])\n",
    "df['block_date'] = pd.to_datetime(df['block_date'])\n",
    "df['block_month'] = pd.to_datetime(df['block_month'])\n",
    "# drop observation if trade_price above max_price or below min_price\n",
    "df = df[(df['trade_price'] <= df['price_max_eth']) & (df['trade_price'] >= df['price_min_eth'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add variables: price_lastsale, time_lastsale\n",
    "# note: dataset is pre-sorted by token_id and block_time\n",
    "df['last_trade_price'] = df.groupby('token_id')['trade_price'].shift(1)\n",
    "df['last_trade_time'] = df.groupby('token_id')['block_time'].shift(1)\n",
    "df['last_trade_timediff'] = df['block_time'] - df['last_trade_time']\n",
    "df['last_trade_timediff'] = df['last_trade_timediff'].dt.total_seconds() / 86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "project                             object\n",
       "version                             object\n",
       "block_date                  datetime64[ns]\n",
       "block_month                 datetime64[ns]\n",
       "block_time             datetime64[ns, UTC]\n",
       "token_id                             int64\n",
       "collection                          object\n",
       "amount_usd                          object\n",
       "token_standard                      object\n",
       "trade_type                          object\n",
       "number_of_items                     object\n",
       "trade_category                      object\n",
       "evt_type                            object\n",
       "trade_price                        float64\n",
       "currency_symbol                     object\n",
       "tx_hash                             object\n",
       "volume_eth                         float64\n",
       "price_p5_eth                       float64\n",
       "price_min_eth                      float64\n",
       "price_max_eth                      float64\n",
       "last_trade_price                   float64\n",
       "last_trade_time        datetime64[ns, UTC]\n",
       "last_trade_timediff                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traits/rarity data\n",
    "from Opensea API: https://docs.opensea.io/reference/get_nft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAYC_ADDRESS = \"0xbc4ca0eda7647a8ab7c2061c2e118a18a936f13d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdrs = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"x-api-key\": OPENSEA_API_KEY\n",
    "    }\n",
    "\n",
    "def get_traits_data(nft_address, token_id, headers=hdrs):\n",
    "\n",
    "    url = f\"https://api.opensea.io/api/v2/chain/ethereum/contract/{nft_address}/nfts/{token_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        data = dict(response.json())\n",
    "    \n",
    "        traits = {}\n",
    "        traits[\"token_id\"] = token_id\n",
    "        traits['rarity_rank'] = data['nft']['rarity']['rank']\n",
    "        for trait_dict in data['nft']['traits']:\n",
    "            trait_type = trait_dict['trait_type']\n",
    "            trait_value = trait_dict['value']\n",
    "            trait_count = trait_dict['trait_count']\n",
    "            traits[trait_type+\"_value\"] = trait_value\n",
    "            traits[trait_type+\"_count\"] = trait_count\n",
    "    \n",
    "    except:\n",
    "        print(f\"An error occurred: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "    return traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_id': 5734,\n",
       " 'rarity_rank': 5411,\n",
       " 'Eyes_value': 'Bloodshot',\n",
       " 'Eyes_count': 846,\n",
       " 'Hat_value': 'Short Mohawk',\n",
       " 'Hat_count': 318,\n",
       " 'Background_value': 'Yellow',\n",
       " 'Background_count': 1283,\n",
       " 'Fur_value': 'Brown',\n",
       " 'Fur_count': 1370,\n",
       " 'Clothes_value': 'Sleeveless Logo T',\n",
       " 'Clothes_count': 144,\n",
       " 'Mouth_value': 'Phoneme Vuh',\n",
       " 'Mouth_count': 333}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_traits_data(BAYC_ADDRESS, 5734)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 494/9045 [00:57<15:39,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 429\n",
      "{\"detail\":\"Request was throttled. Expected available in 0 seconds.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 672/9045 [01:19<16:06,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 429\n",
      "{\"detail\":\"Request was throttled. Expected available in 0 seconds.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 694/9045 [01:22<17:47,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 429\n",
      "{\"detail\":\"Request was throttled. Expected available in 0 seconds.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 3035/9045 [06:17<13:02,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 429\n",
      "{\"detail\":\"Request was throttled. Expected available in 0 seconds.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3226/9045 [06:43<11:45,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 429\n",
      "{\"detail\":\"Request was throttled. Expected available in 0 seconds.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3240/9045 [06:45<12:23,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 429\n",
      "{\"detail\":\"Request was throttled. Expected available in 0 seconds.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9045/9045 [19:08<00:00,  7.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "delay = 0.5 \n",
    "rows = []\n",
    "for id in tqdm(set(df['token_id'].values)):\n",
    "    # sleep & retry if hit rate limit\n",
    "    while True:\n",
    "        traits = get_traits_data(BAYC_ADDRESS, id)\n",
    "        if traits is not None:\n",
    "            rows.append(traits)\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(delay)\n",
    "\n",
    "traits_df = pd.DataFrame(rows)\n",
    "traits_df.to_csv(\"data/bayc_traits.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
